<img src="./imgs/imptox-rgb.png" width="300">

# IMPTOX - WP3 - T3.1.3


## Table of Content:
* [Objectives](#first-bullet)
* [Repository content](#second-bullet)
* [Environment installation](#env-install)
* [Neural Network Training](#third-bullet)
* [GEPARD neural network update procedure](#fourth-bullet)



Data, except for specific tests, are not stored in this repository. The dataset used to train the final version of the resulting particle detector as well as the .pth file compatible with [GEPARD](https://gitlab.ipfdd.de/GEPARD/gepard) can be found [here](https://zenodo.org/uploads/10839527?token=eyJhbGciOiJIUzUxMiJ9.eyJpZCI6Ijc1N2U4NTYxLTIwMDMtNGUxNi1hYmE2LTZkZWEyZDdjZTYzZSIsImRhdGEiOnt9LCJyYW5kb20iOiI5YjIyYTdjMGY1MTI0NTc0YzQyNzAzMTU4NGJjZGU2NSJ9.ARIhpON9L2AVDbNKFbpcTCUt9bBOWwi2PHyHOAdA_GQbpv5oHLpjN3v4oEZRCpsCtR_TLKGjWJwiNfONDFuwfQ). 



## Objectives <a class="anchor" id="first-bullet"></a>

Develop a machine-learning based tool for the reduction of operational time for micro-FTIR and Raman methods. To perform quantification and characterization of MNPs in environmental samples two preparatory steps are performed: digestion of the samples, to remove as many non-plastic materials as possible and filtering. Once a sample is filtered, the remaining particles can be analyzed using Fourier Transform Infrared (FTIR) Microscopy, a technique that combines traditional light microscopy with FTIR spectroscopy, allowing for the chemical analysis of very small structures. The Nicolet™ iN10 Infrared Microscope is a microspectrometer allowing such analysis. Controlled via the OMNIC™ Picta™ software, it is able to automatically collect composed images of the filters and it provides wizards to automatize further analysis, including one for particle detection and identification. 

Industrial software like OMNIC™ Picta™ usually offer little to no flexibility and interacting with the Nicolet™ iN10 Infrared Microscope has proven difficult. To circumvent this, we relied on the work of the Institute of Polymer Research, Dresden which has developed an open-source software called [GEPARD](https://gitlab.ipfdd.de/GEPARD/gepard) allowing image and spectra acquisition on a various set of Raman and FTIR microspectrometers. This control over the micro spectrometer is necessary as our objective is to reduce the operational time for chemical and morphological MNP identification by replacing the current particle detection wizard and spectra acquisition. 

The GEPARD software allows analysis of the images captured by the microscope with either a simple watershed algorithm relying on grey nuances, or with an Artificial Neural Network (ANN) provided with the software. This Neural Network is created using the Detectron2 library, from Facebook AI Research, which provides state-of-the-art detection and segmentation algorithms. However, the originally-provided ANN is trained to detect specific particles on Raman images. So, it is not directly usable for our purpose, and we must train our own ANN using data provided by the FTIR Team from UBFC (WP3). 

---

## Repository content <a class="anchor" id="second-bullet"></a>


This repository contains the main tests, methods and results for task T3.1.3. The first datasets are not available anymore as a curated and final version is provided.

- **01_DataAndNnetV1**: Starting with no annotated images, we used a commercial freeware called [Arivis Cloud](https://www.apeer.com/home/) (previously Apeer) to annotate a subset of available images and create a model based on industry standards. With this black-box model, only usable on the Arivis Cloud platform,  we annotated a set of generated tiles (rectangle images) cut from full-filter images. Once these images were annotated, we used these imperfect but satisfactory annotations as ground-truth to create our own model, using Detectron2, which is compatible with GEPARD. 

- **02_MainPipeline**: In this second iteration, we reproduced the first experiment, using Detectron2, by adding step by step different elements: 

    -  We began by incorporating annotated saturated filters, which are fully covered with material. Ideally, we would analyze the entire surface of these filters using a Focal Plane Array (FPA) detector but such detector was not available. Therefore, we annotated the most prominent particles on several saturated filters. This was done to ensure that our Neural Network, which previously performed well on clean filters, would not fail catastrophically when encountering unfamiliar saturated filters. 

    - To increase the training quality, we then curated the annotations previously automatically generated by Arivis Cloud. This allowed to slightly increase the detection, however this improvement is not measurable as we have no ground truth as even our curated annotations are subject to annotator bias. 

    - Lastly, to further enhance detection, we divided the images and masks into 256px x 256px squares. This size provides finer resolution and prevents image distortion, as the images are automatically resized before being processed by the neural network.

- **03_PyTorchImplementation**: To increase flexibility, we replicated the Detectron2 exercise using basic PyTorch. Detectron2 employs COCO annotations, which match the format of our curated dataset. However, since masks are converted to polygons, there is a resulting loss in resolution.

- **04_DiversTest**:
    - The field of object detection in images has been rapidly evolving in recent years. Choosing a suitable free annotation tool has been challenging due to the frequent introduction of new and useful features, while others remained prohibitively expensive. Our initial choice was "Labelbox," which offered an ergonomic annotation interface, though it required image storage on an S3 infrastructure such as Amazon AWS, Microsoft Azure, or Google Cloud. Our plan was to annotate a few images, create a model from these annotations, and use it to pre-annotate future images. Labelbox supported this workflow, and we attempted Model Assisted Labeling in *01_Labelbox*. To simplify image uploads, we developed a small application to manage storage and interactions with the application in *03_Application_Labelbox*.

    - During the project, Facebook released the SAM (Segment Anything Model), a feature that many annotation tools quickly adopted to enhance annotation speed and quality. In *02_SAM_SegmentAnythingModel*, we explored using SAM directly, but found that the computational power required was too high for our lab computers. In contrast, our small specialized model is lightweight and efficient.

- **envs**:
    - Environment files and installation procedure

---

## Environments installation <a class="anchor" id="env-install"></a>

The project was done mainly on a Linux Ubuntu 20.04 server for the image processing and neural network creation and on a windows machine for GEPARD usage. Three environment were used for this project: 

- The first one contains basic AI and data science packages and mainly Detectron2. To install Detectron2, follow [the documentation](https://detectron2.readthedocs.io/en/latest/tutorials/install.html) to install it directly from the repository. 
- The second one, contains mainly PyTorch related packages. The installation is dependent on your platform and GPUs and it is advised to install PyTorch according to their [website](https://pytorch.org/get-started/locally/). Nevertheless, you will find two files in the [envs](./envs/) folder: 
    - PyTorch_environment.yaml containing main root packages and versions 
    - PyTorch_environment_full.yaml containing all packages and dependencies

- The third one, is the environment needed by GEPARD to run on windows. Here the same installation constraints apply concerning PyTorch. An installation procedure is given [here](./envs/GEPARD_INSTALLATION_PROTOCOL.txt). 

---

## Training and results <a class="anchor" id="third-bullet"></a>

Here is a view of the tensorboard after a 20 epoch training for both Bounding Boxes (bbox) and Segmentation (segm) metrics. . 

![Pytorch Training process Tensorboard](./imgs/PyTorch_Tensorboard_bbox_20epoch.jpg)

![Pytorch Training process Tensorboard](./imgs/PyTorch_Tensorboard_segm_20epoch.jpg)

We can see that the network performs well on a quite classic sample, where the filter (background) is visible in light gray. 

![](./imgs/output1.png)

However, there are still some unexpected behaviours with relatively clean samples. 

![](./imgs/output.png)

As well as with saturated samples. 

![](./imgs/output2.png)

However the network does not fail completely with saturated samples, and with the help of GEPARD and the features mentioned bellow, it is possible to use this neural network with saturated samples. 

![](./imgs/output4.png)


### GEPARD usecase

Fortunately, GEPARD has two vital features that makes the far-fetched detections above not a big problem:

- It allows for manual selection / exclusion of areas of the filter, meaning that empty or blurry areas for instance can be avoided. 
- It allows for size filtering of the detected particles. Meaning that unusually big particles are eliminated. GEPARD manages the image scale by reading the microscope values and thus particle size does not have to be managed by the neural network. 


# GEPARD and Picta result comparision

With OMNIC Picta, the software included with the micro-FTIR microscope, the particle detection wizard allows to detect particles by selecting gray thresholds. This selection has to be performed in two steps: one for the particles lighter than the background filter and one for the darker ones. The detection results are shown bellow. 

With GEPARD however the whole detection can be performed in one step and the detected particles can then be filtered by size and selected or not for further analysis i.e. spectrum capture. 

![](./imgs/picta_1.png)

Particles darker than the background detected with OMNIC Picta

---

![](./imgs/picta_2.png)

Particles lighter than the background detected with OMNIC Picta

---


![](./imgs/gepard_1.png)

Particles detected all at once using GEPARD. 

**Performance of both methods**

Unfortunately, no good comparison method were applied at this moment. To be able to compare GEPARD and OMNIC Picta, we would need to compare the detected particles pixel wide, using e.g. exportable masks, and apply the same spectra identification (corrections, normalization, etc and libraries) to all the particles. All of this of course on more than one sample. However, we were able to compare the two methods in number of particles detected and GEPARD detected ~15\% more particles (1252) than OMNIC PIcta (1083) using the same filter. 

---

# GEPARD - Update Neural Network for FTIR images. <a class="anchor" id="fourth-bullet"></a>

Depending on your sample’s aspect, the neural network needs to be adapted as the one included with GEPARD is used with specific Raman images with a very dark background and light particles. In our case, the samples look like **Figure 1**, with a grey background and darker or lighter particles. It is possible to replace it in a few steps and a simple adaptation in the code. This was tested in both simulation mode and in real conditions. 



<img src="./imgs/filter.JPG" alt="Filter aspect with the Nicolet iN10 FTIR Spectrometer" width="250" height="250">

Figure 1: Filter aspect with the Nicolet iN10 FTIR Spectrometer

## Procedure

- In the GEPARD directory, replace the existing gepard/particledetection/neuralnet/neuralNetWeights.pth file by the new one given with this document. You can either: 

    1. Replace the old file with the new one and rename it “*neuralNetWeights.pth*” or 
    2. Change the file name in the file “*gepard/particledetection/neuralnet/neuralNetSegmentation.py*” at around the line 63: 

        “weightsPath = os.path.join(currentDir, "YOUR_NEW_NAME.pth")”

- In order to have the right output, you need to change the following value from 2 to 1: 

        “cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1”

When testing the neural net segmentation, if the model seems to select the background instead of the particles like in Figure 3, this is where you should look at. 

- GEPARD will send the image cut into 1000px squares to the neural network. This means that you might have a high number of particles in one of this square. For this, you need to update the following line with a number you estimate to be reasonable to ensure that all the particles are all detected: 

        “cfg.TEST.DETECTIONS_PER_IMAGE = 2000”

- The confidence threshold can also be modified to finetune the detection sensitivity:

        “cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1”

- You can also change the size of the square cut that is sent to the Neural Network. The smaller the square, the higher the number of sub-images to analyse and thus the time of analysis. 



### Expected behaviour

Once the update procedure has been done, when using the default neural network you should obtain a detection similar to Figure 2.

Note: the performance and quality of detection might change depending on the size of the mosaic tiles sent to the neural network. This variation of scale, as well as the variation of detection in the border regions, are explored in the report provided within the project. 

![Expected detection result](./imgs/resultOk.JPG)

Figure 2: Expected result for the detection. 

### Possible error

![Error: background is detected instead of particles](./imgs/ResultNeuralNet.JPG)

Figure 3: Reversed detection if the Neural Net output are inverted. 



---



<img src="./imgs/EU-H2020-logo.png" alt="EU logo" width="300">